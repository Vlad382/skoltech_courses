# -*- coding: utf-8 -*-
"""hw2_semantic_segmentation_Trifonov_Vladislav_attempt_1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NcC3WNtc9PoYiMPnB9pKzjVFsg4h_vz3

# Homework 3. Dense Prediction (50 points)
---
In this part, you will study a problem of segmentation. The goal of this assignment is to study, implement, and compare different components of dense prediction models, including **data augmentation**, **backbones**, **classifiers** and **losses**.

This assignment will require training multiple neural networks, therefore it is advised to use a **GPU** accelerator.

<font color='red'>**In this task, it is obligatory to provide accuracy plots on the training and validation datasets obtained during training, as well as examples of the work of each of the models on the images. Without plots, your work will get 0 points. Writing a report is just as important as writing code.**</font>

**<font color='red'>Before the submission please convert your notebook to .py file and check that it runs correctly. How to get .py file in Colab: File -> Download -> Download .py**
"""

# !pip install -U gdown
# !pip install pytorch_lightning

# # Determine the locations of auxiliary libraries and datasets.
# # `AUX_DATA_ROOT` is where 'tiny-imagenet-2022.zip' is.

# # Detect if we are in Google Colaboratory
# try:
#     import google.colab
#     IN_COLAB = True
# except ImportError:
#     IN_COLAB = False

# from pathlib import Path
# if IN_COLAB:
#     google.colab.drive.mount("/content/drive")
    
#     # Change this if you created the shortcut in a different location
#     AUX_DATA_ROOT = Path("/content/drive/My Drive/DL_hw2")
    
#     assert AUX_DATA_ROOT.is_dir(), "Have you forgot to 'Add a shortcut to Drive'?"
    
#     import sys
#     sys.path.append(str(AUX_DATA_ROOT))
# else:
#     AUX_DATA_ROOT = Path(".")

# AUX_DATA_ROOT

# pass a python variable to console in brckets {}
# !ls {'"%s"' % AUX_DATA_ROOT}

# # Uncomment and run if in Colab
# !mkdir datasets
# !cp '{AUX_DATA_ROOT}/tiny-floodnet-challenge.tar.gz' datasets/tiny-floodnet-challenge.tar.gz
# !tar -xzf datasets/tiny-floodnet-challenge.tar.gz -C datasets
# !rm datasets/tiny-floodnet-challenge.tar.gz

# !ls datasets/tiny-floodnet-challenge

"""## Dataset

We will use a simplified version of a [FloodNet Challenge](http://www.classic.grss-ieee.org/earthvision2021/challenge.html).

Compared to the original challenge, our version doesn't have difficult (and rare) "flooded" labels, and the images are downsampled

<img src="https://i.imgur.com/RZuVuVp.png" />

## Assignments and grading


- **Part 1. Code**: fill in the empty gaps (marked with `#TODO`) in the code of the assignment (34 points):
    - `dataset` -- 4 points
    - `model` -- 20 points
    - `loss` -- 8 points
    - `train` -- 2 points
- **Part 2. Train and benchmark** the performance of the required models (6 points):
    - All 6 checkpoints are provided -- 3 points
    - Checkpoints have > 0.5 accuracy -- 3 points
- **Part 3. Report** your findings (10 points)
    - Each task -- 2.5 points

- **Total score**: 50 points.

For detailed grading of each coding assignment, please refer to the comments inside the files. Please use the materials provided during a seminar and during a lecture to do a coding part, as this will help you to further familiarize yourself with PyTorch. Copy-pasting the code from Google Search will get penalized.

In part 2, you should upload all your pre-trained checkpoints to your personal Google Drive, grant public access and provide a file ID, following the intructions in the notebook.

Note that for each task in part 3 to count towards your final grade, you should complete the corresponding tasks in part 2.

For example, if you are asked to compare Model X and Model Y, you should provide the checkpoints for these models in your submission, and their accuracies should be above minimal threshold.

## Part 1. Code

### `dataset`
**TODO: implement and apply data augmentations**

You'll need to study a popular augmentations library: [Albumentations](https://albumentations.ai/), and implement the requested augs. Remember that geometric augmentations need to be applied to both images and masks at the same time, and Albumentations has [native support](https://albumentations.ai/docs/getting_started/mask_augmentation/) for that.
"""

from torch.utils.data import Dataset, DataLoader
import albumentations as A
from torchvision.transforms import ToTensor
import os
from PIL import Image
import numpy as np
import torch



class FloodNet(Dataset):
    """
    Labels semantic:
    0: Background, 1: Building, 2: Road, 3: Water, 4: Tree, 5: Vehicle, 6: Pool, 7: Grass
    """
    def __init__(
        self,
        data_path: str,
        phase: str,
        augment: bool,
        img_size: int,
    ):
        self.num_classes = 8
        self.data_path = data_path
        self.phase = phase
        self.augment = augment
        self.img_size = img_size

        self.items = [filename.split('.')[0] for filename in os.listdir(f'{data_path}/{phase}/image')]
        
        # TODO: implement augmentations (3.5 points)
        if augment:
            # TODO:
            # Random resize
            # Random crop (within image borders, output size = img_size)
            # Random rotation
            # Random horizontal and vertical Flip
            # Random color augmentation
            if self.img_size > 750:
                raise ValueError('Size of the crop is greater than the image size (750x1000).')

            self.transform = A.Compose([A.RandomScale(), A.RandomCrop(width=self.img_size, height=self.img_size),
                                       A.Rotate(), A.Flip(), A.RandomBrightnessContrast()])#, A.RGBShift()])

        else:
        	# TODO: random crop to img_size
            self.transform = A.RandomCrop(width=self.img_size, height=self.img_size)
        
        self.to_tensor = ToTensor()

    def __len__(self):
        return len(self.items)

    def __getitem__(self, index):
        image = np.asarray(Image.open(f'{self.data_path}/{self.phase}/image/{self.items[index]}.jpg'))
        mask = np.asarray(Image.open(f'{self.data_path}/{self.phase}/mask/{self.items[index]}.png'))
        
        if self.phase == 'train':
        	# TODO: apply transform to both image and mask (0.5 points)
            image_mask = self.transform(image=image.copy(), mask=mask.copy())
            image = image_mask['image']
            mask = image_mask['mask']
            # print(type(image), image.shape)
        
        image = self.to_tensor(image.copy())
        mask = torch.from_numpy(mask.copy()).long()

        if self.phase == 'train':
            assert isinstance(image, torch.FloatTensor) and image.shape == (3, self.img_size, self.img_size)
            assert isinstance(mask, torch.LongTensor) and mask.shape == (self.img_size, self.img_size)

        return image, mask

"""### `model`
**TODO: Implement the required models.**

Typically, all segmentation networks consist of an encoder and decoder. Below is a scheme for a popular DeepLab v3 architecture:

<img src="https://i.imgur.com/cdlkxvp.png" />

The encoder consists of a convolutional backbone, typically with extensive use of convs with dilations (atrous convs) and a head, which helps to further boost the receptive field. As you can see, the general idea for the encoders is to have as big of a receptive field, as possible.

The decoder either does upsampling with convolutions (similarly to the scheme above, or to UNets), or even by simply interpolating the outputs of the encoder.

In this assignment, you will need to implement **UNet** and **DeepLab** models. Example UNet looks like this:

<img src="https://i.imgur.com/uVdcE4e.png" />

For **DeepLab** model we will have three variants for backbones: **ResNet18**, **VGG11 (with BatchNorm)**, and **MobileNet v3 (small).** Use `torchvision.models` to obtain pre-trained versions of these backbones and simply extract their convolutional parts. To familiarize yourself with **MobileNet v3** model, follow this [link](https://paperswithcode.com/paper/searching-for-mobilenetv3).

We will also use **Atrous Spatial Pyramid Pooling (ASPP)** head. Its scheme can be seen in the DeepLab v3 architecture above. ASPP is one of the blocks which greatly increases the spatial size of the model, and hence boosts the model's performance. For more details, you can refer to this [link](https://paperswithcode.com/method/aspp).
"""

from torch.nn.modules import activation
from torch.nn.modules.batchnorm import BatchNorm2d
import torch
from torch import nn
from torch.nn import functional as F
from torchvision import models



class UNet(nn.Module):
    """
    TODO: 8 points

    A standard UNet network (with padding in covs).

    For reference, see the scheme in materials/unet.png
    - Use batch norm between conv and relu
    - Use max pooling for downsampling
    - Use conv transpose with kernel size = 3, stride = 2, padding = 1, and output padding = 1 for upsampling
    - Use 0.5 dropout after concat

    Args:
      - num_classes: number of output classes
      - min_channels: minimum number of channels in conv layers
      - max_channels: number of channels in the bottleneck block
      - num_down_blocks: number of blocks which end with downsampling

    The full architecture includes downsampling blocks, a bottleneck block and upsampling blocks

    You also need to account for inputs which size does not divide 2**num_down_blocks:
    interpolate them before feeding into the blocks to the nearest size which divides 2**num_down_blocks,
    and interpolate output logits back to the original shape
    """
    def __init__(self, 
                 num_classes,
                 min_channels=32,
                 max_channels=512, 
                 num_down_blocks=4):
        super(UNet, self).__init__()
        self.num_classes = num_classes
        # TODO
        self.downsample_1 = nn.Sequential(
            nn.Conv2d(in_channels=3, out_channels=min_channels, kernel_size=5, padding=2),
            nn.BatchNorm2d(min_channels),
            nn.ReLU(),
            nn.Conv2d(in_channels=min_channels, out_channels=min_channels, kernel_size=5, padding=2),
            nn.BatchNorm2d(min_channels),
            nn.ReLU(),
        )
        self.downsample_2 = nn.Sequential(
            nn.Conv2d(in_channels=min_channels, out_channels=96, kernel_size=5, padding=2),
            nn.BatchNorm2d(96),
            nn.ReLU(),
            nn.Conv2d(in_channels=96, out_channels=96, kernel_size=5, padding=2),
            nn.BatchNorm2d(96),
            nn.ReLU(),
        )
        self.downsample_3 = nn.Sequential(
            nn.Conv2d(in_channels=96, out_channels=256, kernel_size=3, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(),
            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(),
        )
        self.downsample_4 = nn.Sequential(
            nn.Conv2d(in_channels=256, out_channels=max_channels, kernel_size=3, padding=1),
            nn.BatchNorm2d(max_channels),
            nn.ReLU(),
            nn.Conv2d(in_channels=max_channels, out_channels=max_channels, kernel_size=3, padding=1),
            nn.BatchNorm2d(max_channels),
            nn.ReLU(),
        )
        self.bottleneck = nn.Sequential(
            nn.Conv2d(in_channels=max_channels, out_channels=max_channels, kernel_size=3, padding=1),
            nn.BatchNorm2d(max_channels),
            nn.ReLU(),
            nn.Conv2d(in_channels=max_channels, out_channels=max_channels, kernel_size=3, padding=1),
            nn.BatchNorm2d(max_channels),
            nn.ReLU(),
            # nn.ConvTranspose2d(256, 256, 3, stride=2, padding=1, output_padding=1)
        )
        self.upsample_0 = nn.Sequential(
            nn.Dropout(),
            nn.Conv2d(in_channels=max_channels*2, out_channels=max_channels, kernel_size=3, padding=1),
            nn.BatchNorm2d(max_channels),
            nn.ReLU(),
            nn.Conv2d(in_channels=max_channels, out_channels=max_channels, kernel_size=3, padding=1),
            nn.BatchNorm2d(max_channels),
            nn.ReLU(),
        )
        self.upsample_1 = nn.Sequential(
            nn.Dropout(),
            nn.Conv2d(in_channels=256*2, out_channels=256, kernel_size=3, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(),
            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(),
            # nn.ConvTranspose2d(256, 96, 3, stride=2, padding=1, output_padding=1)
        )
        self.upsample_2 = nn.Sequential(
            nn.Dropout(),
            nn.Conv2d(in_channels=96*2, out_channels=96, kernel_size=3, padding=1),
            nn.BatchNorm2d(96),
            nn.ReLU(),
            nn.Conv2d(in_channels=96, out_channels=96, kernel_size=3, padding=1),
            nn.BatchNorm2d(96),
            nn.ReLU(),
            # nn.ConvTranspose2d(in_channels=96, out_channels=min_channels, kernel_size=3, stride=2, padding=1, output_padding=1)
        )
        self.upsample_3 = nn.Sequential(
            nn.Dropout(),
            nn.Conv2d(in_channels=min_channels*2, out_channels=min_channels, kernel_size=3, padding=1),
            nn.BatchNorm2d(min_channels),
            nn.ReLU(),
            nn.Conv2d(in_channels=min_channels, out_channels=min_channels, kernel_size=3, padding=1),
            nn.BatchNorm2d(min_channels),
            nn.ReLU(),
        )
        self.out = nn.Sequential(
            nn.Conv2d(in_channels=min_channels, out_channels=self.num_classes, kernel_size=1),
            # nn.Sigmoid(),
        )

    def forward(self, inputs):
        flag = False
        device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
        # device = torch.device('cpu')
        num_layers = 4

        # print(inputs.shape, end='\n\n')
        inputs_shape_2 = int(inputs.shape[2])
        inputs_shape_3 = int(inputs.shape[3])
        x_d1 = inputs.clone()

        if inputs_shape_2 % (2 ** num_layers) != 0:
            flag = True
            proper_shape_2 = int(np.round(inputs_shape_2 / 2 ** num_layers) * (2 ** num_layers))
        else: 
            proper_shape_2 = inputs_shape_2

        if inputs_shape_3 % (2 ** num_layers) != 0:
            flag = True
            proper_shape_3 = int(np.round(inputs_shape_3 / 2 ** num_layers) * (2 ** num_layers))
        else:
            proper_shape_3 = inputs_shape_3

        if flag:
            x_d1 = F.interpolate(inputs, (proper_shape_2, proper_shape_3))

        x_d1 = self.downsample_1(x_d1)
        x_d2 = nn.MaxPool2d(kernel_size=2)(x_d1)

        x_d2 = self.downsample_2(x_d2)
        x_d3 = nn.MaxPool2d(kernel_size=2)(x_d2)

        x_d3 = self.downsample_3(x_d3)
        x_d4 = nn.MaxPool2d(kernel_size=2)(x_d3)

        x_d4 = self.downsample_4(x_d4)
        x = nn.MaxPool2d(kernel_size=2)(x_d4)

        x = self.bottleneck(x)
        x = nn.ConvTranspose2d(512, 512, 3, stride=2, padding=1, output_padding=1, device=device)(x)

        x = self.upsample_0(torch.cat([x, x_d4], dim=1))
        x = nn.ConvTranspose2d(512, 256, 3, stride=2, padding=1, output_padding=1, device=device)(x)

        # print(x.shape, x_d3.shape)
        x = self.upsample_1(torch.cat([x, x_d3], dim=1))
        x = nn.ConvTranspose2d(256, 96, 3, stride=2, padding=1, output_padding=1, device=device)(x)

        x = self.upsample_2(torch.cat([x, x_d2], dim=1))
        x = nn.ConvTranspose2d(in_channels=96, out_channels=32, kernel_size=3, stride=2, padding=1, output_padding=1, device=device)(x)

        x = self.upsample_3(torch.cat([x, x_d1], dim=1))
        logits = self.out(x) # TODO

        if flag:
            logits = F.interpolate(logits, (inputs_shape_2, inputs_shape_3))
            # print('2flag', logits.shape)

        # print('!', logits.shape, end='\n\n')
        # print('!', inputs.shape[0], self.num_classes, inputs.shape[2], inputs.shape[3])
        assert logits.shape == (inputs.shape[0], self.num_classes, inputs.shape[2], inputs.shape[3]), 'Wrong shape of the logits'
        return logits


class DeepLab(nn.Module):
    """
    TODO: 6 points

    (simplified) DeepLab segmentation network.
    
    Args:
      - backbone: ['resnet18', 'vgg11_bn', 'mobilenet_v3_small'],
      - aspp: use aspp module
      - num classes: num output classes

    During forward pass:
      - Pass inputs through the backbone to obtain features
      - Apply ASPP (if needed)
      - Apply head
      - Upsample logits back to the shape of the inputs
    """
    def __init__(self, backbone, aspp, num_classes):
        super(DeepLab, self).__init__()
        self.backbone = backbone
        self.num_classes = num_classes
        self.init_backbone()
        self.aspp_bool = aspp

        if self.aspp_bool:
            self.aspp = ASPP(self.out_features, 256, [12, 24, 36])

        self.head = DeepLabHead(self.out_features, num_classes)

    def init_backbone(self):
        # TODO: initialize an ImageNet-pretrained backbone
        if self.backbone == 'resnet18':
            torch_resnet = models.resnet18(pretrained=True)
            self.model_backbone = nn.Sequential(
                torch_resnet.conv1,
                torch_resnet.bn1,
                torch_resnet.relu,
                torch_resnet.maxpool,
                torch_resnet.layer1,
                torch_resnet.layer2,
                torch_resnet.layer3,
                torch_resnet.layer4,
            )
            # print(list(self.model_backbone[-1][-1].bn2.weight.shape)[0])
            self.out_features = list(self.model_backbone[-1][-1].bn2.weight.shape)[0] # TODO: number of output features in the backbone

        elif self.backbone == 'vgg11_bn':
            torch_vgg11_bn = models.vgg11_bn(pretrained=True)

            # print(list(torch_vgg11_bn.features[26].weight.shape)[0])
            self.model_backbone = torch_vgg11_bn.features

            self.out_features = list(torch_vgg11_bn.features[26].weight.shape)[0] # TODO

        elif self.backbone == 'mobilenet_v3_small':
            torch_mobilenet_v3_small = models.mobilenet_v3_small(pretrained=True)
            self.model_backbone = torch_mobilenet_v3_small.features

            # print(list(self.model_backbone[-1][-2].weight.shape)[0])
            self.out_features = list(self.model_backbone[-1][-2].weight.shape)[0] # TODO

    def _forward(self, x):
        # TODO: forward pass through the backbone
        if self.backbone == 'resnet18':
            x = self.model_backbone(x)

        elif self.backbone == 'vgg11_bn':
            x = self.model_backbone(x)

        elif self.backbone == 'mobilenet_v3_small':
            x = self.model_backbone(x)

        return x

    def forward(self, inputs):
        x = self.model_backbone(inputs)

        if self.aspp_bool:
            x = self.aspp(x)

        x = self.head(x)
        
        # print(inputs.shape[2: 4])
        logits = nn.Upsample(size=list(inputs.shape[2: 4]), mode='bilinear')(x)

        assert logits.shape == (inputs.shape[0], self.num_classes, inputs.shape[2], inputs.shape[3]), 'Wrong shape of the logits'
        return logits


class DeepLabHead(nn.Sequential):
    def __init__(self, in_channels, num_classes):
        super(DeepLabHead, self).__init__(
            nn.Conv2d(in_channels, in_channels, 3, padding=1, bias=False),
            nn.BatchNorm2d(in_channels),
            nn.ReLU(),
            nn.Conv2d(in_channels, num_classes, 1)
        )


class ASPP(nn.Module):
    """
    TODO: 8 points

    Atrous Spatial Pyramid Pooling module
    with given atrous_rates and out_channels for each head
    Description: https://paperswithcode.com/method/aspp
    
    Detailed scheme: materials/deeplabv3.png
      - "Rates" are defined by atrous_rates
      - "Conv" denotes a Conv-BN-ReLU block
      - "Image pooling" denotes a global average pooling, followed by a 1x1 "conv" block and bilinear upsampling
      - The last layer of ASPP block should be Dropout with p = 0.5

    Args:
      - in_channels: number of input and output channels
      - num_channels: number of output channels in each intermediate "conv" block
      - atrous_rates: a list with dilation values
    """
    def __init__(self, in_channels, num_channels, atrous_rates):
        super(ASPP, self).__init__()
        self.in_channels = in_channels
        self.num_channels = num_channels
        self.atrous_rates = atrous_rates

    def forward(self, x):
        # TODO: forward pass through the ASPP module
        device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
        # device = torch.device('cpu')

        x_1 = nn.Sequential(
            nn.Conv2d(in_channels=self.in_channels, out_channels=self.num_channels, kernel_size=1),
            nn.BatchNorm2d(self.num_channels),
            nn.ReLU(),
        ).to(device)(x)

        x_2 = nn.Sequential(
            nn.Conv2d(in_channels=self.in_channels, out_channels=self.num_channels, kernel_size=3, dilation=self.atrous_rates[0], padding=self.atrous_rates[0]),
            nn.BatchNorm2d(self.num_channels),
            nn.ReLU(),
        ).to(device)(x)

        x_3 = nn.Sequential(
            nn.Conv2d(in_channels=self.in_channels, out_channels=self.num_channels, kernel_size=3, dilation=self.atrous_rates[1], padding=self.atrous_rates[1]),
            nn.BatchNorm2d(self.num_channels),
            nn.ReLU(),
        ).to(device)(x)
        
        x_4 = nn.Sequential(
            nn.Conv2d(in_channels=self.in_channels, out_channels=self.num_channels, kernel_size=3, dilation=self.atrous_rates[2], padding=self.atrous_rates[2]),
            nn.BatchNorm2d(self.num_channels),
            nn.ReLU(),
        ).to(device)(x)

        # print(x.shape)
        # x_5 = nn.AvgPool2d(kernel_size=list(x.shape)[2:4])(x)
        # print(x_5.shape)
        x_5 = nn.Sequential(
            # torch.mean(input, dim=[2, 3]),
            nn.AvgPool2d(kernel_size=list(x.shape)[2:4]),
            nn.Conv2d(in_channels=self.in_channels, out_channels=self.num_channels, kernel_size=1),
            # nn.BatchNorm2d(self.num_channels),
            nn.ReLU(),
            nn.Upsample(size=list(x_1.shape[2:4]), mode='bilinear')
        ).to(device)(x)

        res = torch.cat([x_1, x_2, x_3, x_4, x_5], dim=1)
        res = nn.Sequential(
            nn.Conv2d(in_channels=list(res.shape)[1], out_channels=x.shape[1], kernel_size=1),
            nn.BatchNorm2d(x.shape[1]),
            nn.ReLU(),
        ).to(device)(res)
        
        res = nn.Upsample(size=list(x.shape[2: 4]))(res)
        res = nn.Dropout(0.5)(res)

        assert res.shape[1] == x.shape[1], 'Wrong number of output channels'
        assert res.shape[2] == x.shape[2] and res.shape[3] == x.shape[3], 'Wrong spatial size'
        return res

"""### `loss`
**TODO: implement test losses.**

For validation, we will use three metrics. 
- Mean intersection over union: **mIoU**,
- Mean class accuracy: **classAcc**,
- Accuracy: **Acc**.

To calculate **IoU**, use this formula for binary segmentation masks for each class, and then average w.r.t. all classes:

$$ \text{IoU} = \frac{ \text{area of intersection} }{ \text{area of union} } = \frac{ \| \hat{m} \cap m  \| }{ \| \hat{m} \cup m \| }, \quad \text{$\hat{m}$ — predicted binary mask},\ \text{$m$ — target binary mask}.$$

Generally, we want our models to optimize accuracy since this implies that it makes little mistakes. However, most of the segmentation problems have imbalanced classes, and therefore the models tend to underfit the rare classes. Therefore, we also need to measure the mean performance of the model across all classes (mean IoU or mean class accuracy). In reality, these metrics (not the accuracy) are the go-to benchmarks for segmentation models.
"""

def calc_val_data(preds, masks, num_classes):
    preds = torch.argmax(preds, dim=1)
    num_batches = preds.shape[0]

    intersection = torch.zeros([num_batches, num_classes]) # TODO: calc intersection for each class
    union = torch.zeros([num_batches, num_classes]) # TODO: calc union for each class
    target = torch.zeros([num_batches, num_classes]) # TODO: calc number of pixels in groundtruth mask per class

    for b in range(num_batches):
        for c in range(num_classes):
            bool_preds_c = torch.eq(preds[b, :, :], c)
            bool_mask_c = torch.eq(masks[b, :, :], c)

            logical_or_res = torch.logical_or(bool_preds_c, bool_mask_c).unique(return_counts=True)
            logical_and_res = torch.logical_and(bool_preds_c, bool_mask_c).unique(return_counts=True)

            if list(logical_or_res[0].shape)[0] == 1:
                if True in logical_or_res[0]:
                    count_union = logical_or_res[1][0].item()
                else:
                    count_union = 0
            else:
                count_union = logical_or_res[1][1].item()

            if list(logical_and_res[0].shape)[0] == 1:
                if True in logical_and_res[0]:
                    count_inter = logical_and_res[1][0].item()
                else:
                    count_inter = 0
            else:
                count_inter = logical_and_res[1][1].item()


            # count_inter = torch.logical_or(bool_preds_c, bool_mask_c).unique(return_counts=True)[1][1].item()
            # count_union = torch.logical_and(bool_preds_c, bool_mask_c).unique(return_counts=True)[1][1].item()

            intersection[b, c] = count_inter
            union[b, c] = count_union

        cl, count = masks[b, :, :].unique(return_counts=True)
        target[b, cl.tolist()] = torch.tensor(count.tolist()).float()
    # print('target', target.shape)
    # Output shapes: B x num_classes

    assert isinstance(intersection, torch.Tensor), 'Output should be a tensor'
    assert isinstance(union, torch.Tensor), 'Output should be a tensor'
    assert isinstance(target, torch.Tensor), 'Output should be a tensor'

    assert intersection.shape == union.shape == target.shape, 'Wrong output shape'
    assert union.shape[0] == masks.shape[0] and union.shape[1] == num_classes, 'Wrong output shape'

    return intersection, union, target

def calc_val_loss(intersection, union, target, eps = 1e-7):
    mean_iou = torch.mean(intersection.sum(dim=0) / (union.sum(dim=0) + eps)).item() # TODO: calc mean class iou
    mean_class_rec = torch.mean(intersection.sum(dim=0) / target.sum(dim=0)).item() # TODO: calc mean class recall
    # print(intersection.sum(), target.sum())

    mean_acc = torch.mean((intersection.sum(dim=0) + (target.sum() - union.sum(dim=0))) / target.sum()).item()
    # mean_acc = (intersection.sum() / target.sum()).item() # TODO: calc mean accuracy

    return mean_iou, mean_class_rec, mean_acc

"""### `train`
**TODO: define optimizer and learning rate scheduler.**

You need to experiment with different optimizers and schedulers and pick one of each which works the best. Since the grading will be partially based on the validation performance of your models, we strongly advise doing some preliminary experiments and pick the configuration with the best results.
"""

# Copyright The PyTorch Lightning team.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Modifications Copyright Skoltech Deep Learning Course.

import torch
import torch.nn.functional as F
import pytorch_lightning as pl
from torch.utils.data import DataLoader

# from .model import UNet, DeepLab
# from .dataset import FloodNet
# from . import loss



class SegModel(pl.LightningModule):
    def __init__(
        self,
        model: str,
        backbone: str,
        aspp: bool,
        augment_data: bool,
        optimizer: str = 'default',
        scheduler: str = 'default',
        lr: float = None,
        batch_size: int = 16,
        data_path: str = 'datasets/tiny-floodnet-challenge',
        image_size: int = 256,
    ):
        super(SegModel, self).__init__()
        self.num_classes = 8

        if model == 'unet':
            self.net = UNet(self.num_classes)
        elif model == 'deeplab':
            self.net = DeepLab(backbone, aspp, self.num_classes)

        self.train_dataset = FloodNet(data_path, 'train', augment_data, image_size)
        self.test_dataset = FloodNet(data_path, 'test', augment_data, image_size)

        self.batch_size = batch_size
        self.optimizer = optimizer
        self.scheduler = scheduler
        self.lr = lr
        self.eps = 1e-7

        # Visualization
        self.color_map = torch.FloatTensor(
            [[0, 0, 0], [0, 0, 1], [0, 1, 0], [0, 1, 1],
             [1, 0, 0], [1, 0, 1], [1, 1, 0], [1, 1, 1]])

    def forward(self, x):
        return self.net(x)

    def training_step(self, batch, batch_idx):
        img, mask = batch
        pred = self.forward(img)

        # print('pred', pred.shape)
        # print('mask', mask.shape)
        train_loss = F.cross_entropy(pred, mask)

        self.log('train_loss', train_loss, prog_bar=True)

        return train_loss

    def validation_step(self, batch, batch_idx):
        img, mask = batch
        pred = self.forward(img)

        intersection, union, target = calc_val_data(pred, mask, self.num_classes)###########

        val_loss = F.cross_entropy(pred, mask)
        self.log('val_loss', val_loss, prog_bar=True)

        return {'intersection': intersection, 'union': union, 'target': target, 'img': img, 'pred': pred, 'mask': mask}

    def validation_epoch_end(self, outputs):
        intersection = torch.cat([x['intersection'] for x in outputs])
        union = torch.cat([x['union'] for x in outputs])
        target = torch.cat([x['target'] for x in outputs])

        mean_iou, mean_class_rec, mean_acc = calc_val_loss(intersection, union, target, self.eps)###############

        log_dict = {'mean_iou': mean_iou, 'mean_class_rec': mean_class_rec, 'mean_acc': mean_acc}

        for k, v in log_dict.items():
            self.log(k, v, prog_bar=True)

        # Visualize results
        img = torch.cat([x['img'] for x in outputs]).cpu()
        pred = torch.cat([x['pred'] for x in outputs]).cpu()
        mask = torch.cat([x['mask'] for x in outputs]).cpu()

        pred_vis = self.visualize_mask(torch.argmax(pred, dim=1))
        mask_vis = self.visualize_mask(mask)

        results = torch.cat(torch.cat([img, pred_vis, mask_vis], dim=3).split(1, dim=0), dim=2)
        results_thumbnail = F.interpolate(results, scale_factor=0.25, mode='bilinear')[0]

        self.logger.experiment.add_image('results', results_thumbnail, self.current_epoch)

    def visualize_mask(self, mask):
        b, h, w = mask.shape
        mask_ = mask.view(-1)

        if self.color_map.device != mask.device:
            self.color_map = self.color_map.to(mask.device)

        mask_vis = self.color_map[mask_].view(b, h, w, 3).permute(0, 3, 1, 2).clone()

        return mask_vis

    def configure_optimizers(self):
        # TODO: 2 points
        # Use self.optimizer and self.scheduler to call different optimizers
        opt_dict = {
            'default': torch.optim.SGD(self.net.parameters(), lr=self.lr, momentum=0.9),
            'adam_0': torch.optim.Adam(self.net.parameters(), lr=self.lr),
            'adamax_0': torch.optim.Adamax(self.net.parameters(), lr=self.lr),
            'sgd_wd': torch.optim.SGD(self.net.parameters(), lr=self.lr, momentum=0.9, weight_decay=1e-5),
            'adam_wd': torch.optim.Adam(self.net.parameters(), lr=self.lr, weight_decay=1e-5),
        }
        opt = opt_dict[self.optimizer] # TODO: init optimizer

        sch_dict = {
            'default': torch.optim.lr_scheduler.MultiStepLR(opt, [10, 20, 30], gamma=0.1)
        }
        sch = sch_dict[self.scheduler] # TODO: init learning rate scheduler

        return [opt], [sch]

    def train_dataloader(self):
        return DataLoader(self.train_dataset, num_workers=8, batch_size=self.batch_size, shuffle=True)

    def val_dataloader(self):
        return DataLoader(self.test_dataset, num_workers=8, batch_size=1, shuffle=False)

"""## Part 2. Train and benchmark

In this part of the assignment, you need to train the following models and measure their training time:
- **UNet** (with and without data augmentation),
- **DeepLab** with **ResNet18** backbone (with **ASPP** = True and False),
- **DeepLab** with the remaining backbones you implemented and **ASPP** = True).

To get the full mark for this assignment, all the required models should be trained (and their checkpoints provided), and have at least 0.5 accuracies.

After the models are trained, evaluate their inference time on both GPU and CPU.

Example training and evaluation code are below.
"""

import pytorch_lightning as pl
# from semantic_segmentation.train import SegModel
import time
import torch


def define_model(model_name: str, 
                 backbone: str, 
                 aspp: bool, 
                 augment_data: bool, 
                 optimizer: str, 
                 scheduler: str, 
                 lr: float, 
                 checkpoint_name: str = '', 
                 batch_size: int = 16):
    assignment_dir = 'semantic_segmentation'
    experiment_name = f'{model_name}_{backbone}_augment={augment_data}_aspp={aspp}'
    model_name = model_name.lower()
    backbone = backbone.lower() if backbone is not None else backbone
    
    model = SegModel(
        model_name, 
        backbone, 
        aspp, 
        augment_data,
        optimizer,
        scheduler,
        lr,
        batch_size, 
        data_path='datasets/tiny-floodnet-challenge', 
        image_size=256)

    if checkpoint_name:
        model.load_state_dict(torch.load(f'{assignment_dir}/logs/{experiment_name}/{checkpoint_name}')['state_dict'])
    
    return model, experiment_name

def train(model, experiment_name, use_gpu):
    assignment_dir = 'semantic_segmentation'

    logger = pl.loggers.TensorBoardLogger(save_dir=f'{assignment_dir}/logs', name=experiment_name)

    checkpoint_callback = pl.callbacks.ModelCheckpoint(
        monitor='mean_iou',
        dirpath=f'{assignment_dir}/logs/{experiment_name}',
        filename='{epoch:02d}-{mean_iou:.3f}',
        mode='max')
    
    trainer = pl.Trainer(
        max_epochs=50, 
        gpus=1 if use_gpu else None, 
        benchmark=True, 
        check_val_every_n_epoch=5, 
        logger=logger, 
        callbacks=[checkpoint_callback])

    time_start = time.time()
    
    trainer.fit(model)
    
    torch.cuda.synchronize()
    time_end = time.time()
    
    training_time = (time_end - time_start) / 60
    
    return training_time

# model, experiment_name = define_model(
#     model_name='deeplab',
#     backbone='mobilenet_v3_small',
#     aspp=True,
#     augment_data=True,
#     optimizer='adam_0', # use these options to experiment
#     scheduler='default', # with optimizers and schedulers
#     lr=1e-3) # experiment to find the best LR
# training_time = train(model, experiment_name, use_gpu=True
# )

# print(f'Training time: {training_time:.3f} minutes')

"""After training, the loss curves and validation images with their segmentation masks can be viewed using the TensorBoard extension:"""

runs = {
    'run_1': {'model_name': 'UNet', 'backbone': None, 'aspp': None, 'augment_data': False},
    'run_2': {'model_name': 'UNet', 'backbone': None, 'aspp': None, 'augment_data': True},
    'run_3': {'model_name': 'deeplab', 'backbone': 'resnet18', 'aspp': False, 'augment_data': True},
    'run_4': {'model_name': 'deeplab', 'backbone': 'resnet18', 'aspp': True, 'augment_data': True},
    'run_5': {'model_name': 'deeplab', 'backbone': 'vgg11_bn', 'aspp': True, 'augment_data': True},
    'run_6': {'model_name': 'deeplab', 'backbone': 'mobilenet_v3_small', 'aspp': True, 'augment_data': True},
}

for r in runs.keys():
    model, experiment_name = define_model(
        **runs[r],
        optimizer='adam_0', # use these options to experiment
        scheduler='default', # with optimizers and schedulers
        lr=1e-3) # experiment to find the best LR

    training_time = train(model, experiment_name, use_gpu=True)

    print(f'Training time: {training_time:.3f} minutes. Run: {r}')

# %load_ext tensorboard
# %tensorboard --logdir /content/semantic_segmentation/logs

# !zip -r /content/log_hw2_part1.zip /content/semantic_segmentation/
# from google.colab import files
# files.download("/content/log_hw2_part1.zip")

"""Inference time can be measured via the following function:"""

def calc_inference_time(model, device, input_shape=(1000, 750), num_iters=100):
    timings = []

    for i in range(num_iters):
        x = torch.randn(1, 3, *input_shape).to(device)
        time_start = time.time()
        
        model(x)
        
        torch.cuda.synchronize()
        time_end = time.time()
        
        timings.append(time_end - time_start)

    return sum(timings) / len(timings) * 1e3

# runs_with_checpoints = {
#     'run_1': {'model_name': 'UNet', 'backbone': None, 'aspp': None, 'augment_data': False, 'checkpoint_name': 'epoch=29-mean_iou=0.215.ckpt'},
#     'run_2': {'model_name': 'UNet', 'backbone': None, 'aspp': None, 'augment_data': True, 'checkpoint_name': 'epoch=04-mean_iou=0.280.ckpt'},
#     'run_3': {'model_name': 'deeplab', 'backbone': 'resnet18', 'aspp': False, 'augment_data': True, 'checkpoint_name': 'epoch=49-mean_iou=0.341.ckpt'},
#     'run_4': {'model_name': 'deeplab', 'backbone': 'resnet18', 'aspp': True, 'augment_data': True, 'checkpoint_name': 'epoch=39-mean_iou=0.086.ckpt'},
#     'run_5': {'model_name': 'deeplab', 'backbone': 'vgg11_bn', 'aspp': True, 'augment_data': True, 'checkpoint_name': 'epoch=14-mean_iou=0.099.ckpt'},
#     'run_6': {'model_name': 'deeplab', 'backbone': 'mobilenet_v3_small', 'aspp': True, 'augment_data': True, 'checkpoint_name': 'epoch=39-mean_iou=0.102.ckpt'},
# }


# for run in runs_with_checpoints.keys():
#     model = define_model(**runs_with_checpoints[run], optimizer='adam_0', scheduler='default', lr=1e-3)

#     inference_time = calc_inference_time(model[0].eval().cpu(), 'cpu', num_iters=10)
#     print(f'CPU. Run: {run}. Inferece time (per frame): {inference_time:.3f} ms')

# for run in runs_with_checpoints.keys():
#     model = define_model(**runs_with_checpoints[run], optimizer='adam_0', scheduler='default', lr=1e-3)

#     inference_time = calc_inference_time(model[0].eval().cuda(), 'cuda')
#     print(f'GPU. Run: {run}. Inferece time (per frame): {inference_time:.3f} ms')

"""Your trained weights are available in the `part1_semantic_segmentation/logs` folder. Inside, your experiment directory has a log file with the following mask: `{epoch:02d}-{mean_iou:.3f}.ckpt`. <font color='red'>**Make sure that you models satisfy the accuracy requirements, upload them to your personal Google Drive, and provide a link to google drive folder**."""

checkpoint_names = {
    'UNet_None_augment=False_aspp=None.ckpt',
    'UNet_None_augment=True_aspp=None.ckpt',
    'DeepLab_ResNet18_augment=True_aspp=False.ckpt',
    'DeepLab_ResNet18_augment=True_aspp=True.ckpt',
    'DeepLab_VGG11_bn_augment=True_aspp=True.ckpt',
    'DeepLab_MobileNet_v3_small_augment=True_aspp=True.ckpt',
}

"""## Part 3. Report

You should have obtained 7 different models, which we will use for the comparison and evaluation. When asked to visualize specific loss curves, simply configure these plots in TensorBoard, screenshot, store them in the `report` folder, and load into Jupyter markdown:

`<img src="./part1_semantic_segmentation/report/<screenshot_filename>"/>`

If you have problems loading these images, try uploading them [here](https://imgur.com) and using a link as `src`. Do not forget to include the raw files in the `report` folder anyways.

You should make sure that your plots satisfy the following requirements:
- Each plot has a title,
- If there are multiple curves on one plot (or dots on the scatter plot), the plot legend should also be present,
- If the plot is not obtained using TensorBoard (Task 3), the axis should have names and ticks.

<font color='red'>**In this task, it is obligatory to provide accuracy plots on the training and validation datasets obtained during training, as well as examples of the work of each of the models on the images. Without plots, your work will get 0 points. Writing a report is just as important as writing code.**</font>

#### Task 1.
Visualize training loss and validation loss curves for UNet trained with and without data augmentation. What are the differences in the behavior of these curves between these experiments, and what are the reasons?

First things first:

1. [Link](https://drive.google.com/drive/folders/1xurXUXR5mhOaW2K9FbXbtQRLEOnIbDrx?usp=sharing) to the folder with weights

2. [Link](https://drive.google.com/drive/folders/1oBJLFO2wgPVzR0Ecfvry3LWlk5NBe3le?usp=sharing) to the pictures

|<img src="https://drive.google.com/uc?id=1qZ8dy84EcQHUIeSHS4CaWP34xIMOBKEq"/>|<img src="https://drive.google.com/uc?id=19JWt-XsTBZm6KwsoEfx0ztPP7GEzwPpf"/>|<img src="https://drive.google.com/uc?id=1agvxs6fdxyIFZx5KmwRONjbHf7atoU7i"/>|
|:--:|:--:|:--:|
| *Orange - UNet without augmentation, Blue - UNet with augmentation* | *Orange - UNet without augmentation, Blue - UNet with augmentation* | *Orange - UNet without augmentation, Blue - UNet with augmentation* |

|<img src="https://drive.google.com/uc?id=14yx1-dimDGal3ILzud8bFF22ZDsHyKGg"/>|<img src="https://drive.google.com/uc?id=1xT2FozvoFcjnsV9SdjVCiYRzlNl-5m95"/>|
|:--:|:--:|
| *Orange - UNet without augmentation, Blue - UNet with augmentation* | *Orange - UNet without augmentation, Blue - UNet with augmentation* |

The main differenct obviously that model with augmentation is less suffer from overfitting and hence has all metrics better. What is interesting, that mean accuracy, mean call recall and mean IoU curves both have the similar geometry from some point. From this I can make and assumption, that augmentation for the UNet increase not only overall score (accuracy), but is also sensitive to the fact that this porblem is imbalanced.

Train loss is nor really representative and both experiments behave in the same way for it. Validation loss stabilize very fast for both experiments and then only oscillate around achived value.

#### Task 2.
Visualize training and validation loss curves for ResNet18 trained with and without ASPP. Which model performs better?

|<img src="https://drive.google.com/uc?id=1xJ0Luo9iULonCZ8fNHCbrQgqFLhfkrRo"/>|<img src="https://drive.google.com/uc?id=1B2gTpkrNnprpwLa2FmeQzkSnsn46iXNc"/>|<img src="https://drive.google.com/uc?id=1GLyhxJye46RsY1EkShBI2bPaNtcq49ss"/>|
|:--:|:--:|:--:|
| *Light blue - Deeplab/ResNet with ASPP, Red - Deeplab/ResNet without ASPP* | *Light blue - Deeplab/ResNet with ASPP, Red - Deeplab/ResNet without ASPP* | *Light blue - Deeplab/ResNet with ASPP, Red - Deeplab/ResNet without ASPP* |

|<img src="https://drive.google.com/uc?id=18R_iqgFijUdil7p2TWAFNVVj61u9qwm3"/>|<img src="https://drive.google.com/uc?id=1P_S1IahSpMwteulMccyqnyrzf5Hshk33"/>|
|:--:|:--:|
| *Light blue - Deeplab/ResNet with ASPP, Red - Deeplab/ResNet without ASPP* | *Light blue - Deeplab/ResNet with ASPP, Red - Deeplab/ResNet without ASPP* |

For DeepLab/ResNet with and without ASPP the behavior of the metrics differes a lot on the different experiments. First of all, the metrics (mean accuracy, mean class recall and mean IoU) are way better for the case without ASPP. It strat growing faster from the very beginning and may be even have a trand to grow further (could not accomplish longer experiment).

Case with ASPP the metrics achieve its maximum and do not grow from the very beginnig of the training.

Training loss for the DeepLab/ResNet with and without ASPP differes a little and one model can be distinguished from another. Validation loss for case with ASPP freeze very fast, but for case without ASPP it drops significantly during training.

#### Task 3.
Compare **UNet** with augmentations and **DeepLab** with all backbones (only experiments with **ASPP**). To do that, put these models on three scatter plots. For the first plot, the x-axis is **training time** (in minutes), for the second plot, the x-axis is **inference time** (in milliseconds), and for the third plot, the x-axis is **model size** (in megabytes). The size of each model is printed by PyTorch Lightning. For all plots, the y-axis is the best **mIoU**. To clarify, each of the **4** requested models should be a single dot on each of these plots.

Which models are the most efficient with respect to each metric on the x-axes? For each of the evaluated models, rate its performance using their validation metrics, training and inference time, and model size. Also for each model explain what are its advantages, and how its performance could be improved?

<img src="https://drive.google.com/uc?id=1ZYe3aXP4-EFfa8mKO0dpC_Z2wpx9oOlc"/>

Altough the training time for UNet is the highest, its performance is way better than for DeepLab models. 

Inference time for DeepLab/Mobilenet is the same for both cpu and gpu runs. It means that it really can be used on a local machine without gpu. What is also worth to mention here, that it performs better than other DeepLab models. For gpu is obviously the inference time for UNet is not that much higher. On the other hand, inference time on cpu for UNet is really way higher. I would like to say, that DeepLab/Mobilenet is better than UNet in terms of inference time, but the difference in IoU scores still side me to the UNet.

In terms of models size the DeepLab/Mobilenet is the best. If we combaine the results of the 3rd and 2nd plots, than DeepLab/Mobilenet is really a good choice when you need to perform calculationf on the local mahcine. Unet size is huge if compare to DeepLab/Mobilenet.

DeepLab/ResNet and DeepLab/Vgg are both worse in all metrics if comapre with DeepLab/Mobilenet.

|<img src="https://drive.google.com/uc?id=1-vl_9LIC43xanJBFY4p7qZhlWuCmrzZ6"/>|<img src="https://drive.google.com/uc?id=1D5NafWO0Fi98lHpXHowT1E9PObdvWjwj"/>|<img src="https://drive.google.com/uc?id=1MdTCEhpcwAYYxKVKf_IG0rTKAQoMeaXj"/>|
|:--:|:--:|:--:|
| *Blue - UNet, Light Blue - DeepLab/ResNet, Purple - DeepLab/VGG, Green - DeepLab/MobileNet* | *Blue - UNet, Light Blue - DeepLab/ResNet, Purple - DeepLab/VGG, Green - DeepLab/MobileNet* | *Blue - UNet, Light Blue - DeepLab/ResNet, Purple - DeepLab/VGG, Green - DeepLab/MobileNet* |

|<img src="https://drive.google.com/uc?id=1rtDGn9nv4AFCyaXh9_kDunKHR8ySqne_"/>|<img src="https://drive.google.com/uc?id=1d_sOT0wewiictOjIlbcAQYMrKQnaCGB3"/>|
|:--:|:--:|
| *Blue - UNet, Light Blue - DeepLab/ResNet, Purple - DeepLab/VGG, Green - DeepLab/MobileNet* | *Blue - UNet, Light Blue - DeepLab/ResNet, Purple - DeepLab/VGG, Green - DeepLab/MobileNet* |

I find it really interesting that the metrics for DeepLab models stop growth really fast and that the training loss is comparable for all the experiments (not totally, but somehow I think it's true). Also the drop for UNet in the very beginning is also not clear for me.

**How models can be improved**

UNet. I would say that first thing to play with number of down/up-scale blocks and with number of channels within it. So, may be we can achive the same scores but with lighter models with less time for training.

DeepLab models. May be simplified DeepLab is not the best choice. If I am not mistaken, results of backbone should be concatetaed with results of ASPP (not just apply ASPP), and head is a bit more complicated. Also, backbones may has some excess of layers (adjust the choice of layers from torchs' zoo models).

Of course, to fine tune parameters. Choose a proper optimizer, augmentation, scheduler, etc.
"""

# import matplotlib.pyplot as plt
# %matplotlib inline

# #models to comapre: unet and deeplab with aspp (all with augmentation)
# train_time = [34.27, 13.58, 16.37, 12.64] # in minutes
# inference_time_cpu = [14402, 1563, 4177, 564] # miliseconds
# inference_time_gpu = [681, 96, 240, 81] # miliseconds
# model_size = [74.167, 54.164, 46.36, 15.68] # megabytes

# y_axis = [0.280, 0.086, 0.099, 0.102] # the best mIoU
# colors = ['r', 'b', 'g', 'k']
# labels = ['UNet', 'DeepLab/resnet18', 'DeepLab/vgg1_bn', 'DeepLab/mobilenet_v3_small']

# _, axes = plt.subplots(3, 1, figsize=(8, 16))

# for i in range(4):
#     axes[0].scatter(train_time[i], y_axis[i], color=colors[i], label=labels[i], s=100)
#     axes[1].scatter(inference_time_cpu[i], y_axis[i], color=colors[i], label=labels[i]+'/cpu', s=100)
#     axes[1].scatter(inference_time_gpu[i], y_axis[i], color=colors[i], label=labels[i]+'/gpu', marker='s', s=100)
#     axes[2].scatter(model_size[i], y_axis[i], color=colors[i], label=labels[i], s=100)

# axes[0].set_title('Train time')
# axes[1].set_title('Inference time')
# axes[2].set_title('Model size')

# axes[0].set_xlabel('Train time, minutes')
# axes[1].set_xlabel('Inference time, miliseconds')
# axes[2].set_xlabel('Model size, mb')

# for i in range(3):
#     axes[i].legend()
#     axes[i].set_ylabel('mIoU')
#     axes[i].grid()

"""#### Task 4.

Pick the best model according to **mIoU** and look at the visualized predictions on the validation set in the TensorBoard. For each segmentation class, find the good examples (if they are available), and the failure cases. Provide the zoomed-in examples and their analysis below. Please do not attach full validation images, only the areas of interest which you should crop manually.

|<img src="https://drive.google.com/uc?id=1Y04DEmPz_h6NEHUgqK8yILQxYiU6qHLX"/>|<img src="https://drive.google.com/uc?id=1_gOf7zuc596qbPeo78Jg-DexXbDLrozj"/>|<img src="https://drive.google.com/uc?id=1B0Dq8L_3qkSVPvgLIIVD4qNuFtJZ8wD-"/>|
|:--:|:--:|:--:|
| *True mask* | *Predicted mask* | *Picture* |

Here the model predicts the grass where is building on the picture.

---

|<img src="https://drive.google.com/uc?id=14t22VHVr0m9ObKH-9BCzQnp_oSbIx1gn"/>|<img src="https://drive.google.com/uc?id=1cq4t_MLUu8YjVOZ9HI86oeIKtrmCEjJH"/>|<img src="https://drive.google.com/uc?id=1lPDur6HUC61e9L6zkvigYwOp6LNIWHjJ"/>|
|:--:|:--:|:--:|
| *True mask* | *Predicted mask* | *Picture* |

When there are a lot details model can't handle them. Also no car was predicted properly.

---

|<img src="https://drive.google.com/uc?id=1nOVvcQKwfHXCOyJPxmLYdxgG9o0WW29N"/>|<img src="https://drive.google.com/uc?id=12coZYjVVtnTO9S1cvUF8ajOQ_td5UQwl"/>|<img src="https://drive.google.com/uc?id=1dQIJm5MjClVd5K0rVfQwNEqtLtLfhGiw"/>|
|:--:|:--:|:--:|
| *True mask* | *Predicted mask* | *Picture* |

Here is and example how the building was predicted in the middle of the river near the bridge. Overall river is predicted properly.

---

|<img src="https://drive.google.com/uc?id=1PqSg8EqvzrRtvmTPyBYmJ6p16tj7Z9Hu"/>|<img src="https://drive.google.com/uc?id=1q1bVPA6VE3q-vRQHi7NBXWC267NKxa0Y"/>|<img src="https://drive.google.com/uc?id=184HoNfccqYD6opMYL2g7rOsOBTebtgbp"/>|
|:--:|:--:|:--:|
| *True mask* | *Predicted mask* | *Picture* |

The model can't comprehend the flooded areas along a road.

---

|<img src="https://drive.google.com/uc?id=1EVRKIvgwJIju09D5Iz2d_W7PdZrkby2A"/>|<img src="https://drive.google.com/uc?id=1MikaVCPz_H8QYKjn68xHSJl1edHSkYO_"/>|<img src="https://drive.google.com/uc?id=1t5XyJsfafRQubvxawVFML6EWCC2A-P67"/>|
|:--:|:--:|:--:|
| *True mask* | *Predicted mask* | *Picture* |

Another example how cars are not identified.

---

|<img src="https://drive.google.com/uc?id=1KsT3j9aIsu0AmdYo6fJOAQwpApx3Ka2R"/>|<img src="https://drive.google.com/uc?id=1Kdz83ZBRaRe-iQkgKoE8n9hNvxqo30p5"/>|<img src="https://drive.google.com/uc?id=1D_mR2sUaG4Y-TT7KyMJ-BbbFAxKYluOv"/>|
|:--:|:--:|:--:|
| *True mask* | *Predicted mask* | *Picture* |

The model predicted no pools properly.

---

|<img src="https://drive.google.com/uc?id=1j6nERyaH2yWa5z43ef4itOQsEkx6r2hH"/>|<img src="https://drive.google.com/uc?id=14LI2fEArllEFRVftvTxe069gN9hG5EYs"/>|<img src="https://drive.google.com/uc?id=1aCXMMK8gXpTEaqJs-YcDgJokfayqtX3L"/>|
|:--:|:--:|:--:|
| *True mask* | *Predicted mask* | *Picture* |

The shadow of trees was confused with the flooded area.

---

|<img src="https://drive.google.com/uc?id=1ysTn_tp_3ixrKPMm-4jyLWyjbzCqCmdm"/>|<img src="https://drive.google.com/uc?id=1wDeCdXFgcnhPQU0nZlCr2zisDOmF1V2t"/>|<img src="https://drive.google.com/uc?id=1DZ7c3H1pwPpy_H2m-QQOw9eCs4jVKNYw"/>|
|:--:|:--:|:--:|
| *Picture 1* | *Picture 2* | *Picture 3* |

These three pictures illustrate that model can handle the overall geometry on the picture pretty good. Areas with buildings, trees and grass can be used to unequivocally define the inital picture.

**<font color='red'>Before the submission please convert your notebook to .py file and check that it runs correctly. How to get .py file in Colab: File -> Download -> Download .py**
Left side menu in Colab -> Files -> Upload your script
and then check.
"""

# !python hw2_semantic_segmentation_trifonov_vladislav_attempt_1.py

"""You can replace TODO strings to None"""